{"cells":[{"cell_type":"markdown","metadata":{},"source":["## üôå Inspiration and Credits\n","## ------------------------------\n","\n"," This notebook draws inspiration from the exceptional work of mbanaei (@mbanaei) which can be found here: [Link to mbanaei's Notebook](https://www.kaggle.com/code/mbanaei/86-2-with-only-270k-articles).\n","\n","## üåü Explore My Profile\n","## ------------------------------\n"," If you found this notebook valuable and insightful, I invite you to explore my Kaggle profile and other public projects for more exciting content and solutions:\n"," üëâ [Visit my Kaggle Profile](https://www.kaggle.com/zulqarnainali) üëà\n","\n","## üôè Thank You\n","# ------------------------------\n"," Your time and attention are greatly appreciated. If you found this work helpful or insightful, please consider giving it a thumbs-up to show your support and appreciation! üëç\n","## How to Use üõ†Ô∏è\n","To use this notebook effectively, please follow these steps:\n","\n","Ensure you have the competition data and environment set up.\n","Execute each cell sequentially to perform data preparation, feature engineering, model training, and prediction submission.\n","Customize and adapt the code as needed to improve model performance or experiment with different approaches.\n","\n","Note: Make sure to replace any placeholder paths or configurations with your specific information."]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-04T20:49:35.075001Z","iopub.status.busy":"2023-10-04T20:49:35.074486Z","iopub.status.idle":"2023-10-04T20:49:35.091449Z","shell.execute_reply":"2023-10-04T20:49:35.090700Z","shell.execute_reply.started":"2023-10-04T20:49:35.074969Z"},"trusted":true},"outputs":[],"source":["# üì¶ Import necessary libraries and modules for data manipulation and processing.\n","%load_ext autoreload\n","%autoreload 2\n","import numpy as np\n","import pandas as pd\n","from datasets import load_dataset, load_from_disk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","from transformers import LongformerTokenizer, LongformerForMultipleChoice\n","import transformers\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import unicodedata\n","\n","# üìÇ Import the \"os\" module for operating system-related functionality.\n","import os\n","import gc"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# üõë Define a list of stop words to be used in text processing.\n","stop_words = ['each', 'you', 'the', 'use', 'used',\n","                  'where', 'themselves', 'nor', \"it's\", 'how', \"don't\", 'just', 'your',\n","                  'about', 'himself', 'with', \"weren't\", 'hers', \"wouldn't\", 'more', 'its', 'were',\n","                  'his', 'their', 'then', 'been', 'myself', 're', 'not',\n","                  'ours', 'will', 'needn', 'which', 'here', 'hadn', 'it', 'our', 'there', 'than',\n","                  'most', \"couldn't\", 'both', 'some', 'for', 'up', 'couldn', \"that'll\",\n","                  \"she's\", 'over', 'this', 'now', 'until', 'these', 'few', 'haven',\n","                  'of', 'wouldn', 'into', 'too', 'to', 'very', 'shan', 'before', 'the', 'they',\n","                  'between', \"doesn't\", 'are', 'was', 'out', 'we', 'me',\n","                  'after', 'has', \"isn't\", 'have', 'such', 'should', 'yourselves', 'or', 'during', 'herself',\n","                  'doing', 'in', \"shouldn't\", \"won't\", 'when', 'do', 'through', 'she',\n","                  'having', 'him', \"haven't\", 'against', 'itself', 'that',\n","                  'did', 'theirs', 'can', 'those',\n","                  'own', 'so', 'and', 'who', \"you've\", 'yourself', 'her', 'he', 'only',\n","                  'what', 'ourselves', 'again', 'had', \"you'd\", 'is', 'other',\n","                  'why', 'while', 'from', 'them', 'if', 'above', 'does', 'whom',\n","                  'yours', 'but', 'being', \"wasn't\", 'be',\n","                  \"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won']\n","\n","option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n","index_to_option = {v: k for k,v in option_to_index.items()}\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# def whoosh_retrieval(df_valid, search_engine):\n","    \n","#     corpus_df_valid = df_valid.apply(lambda row:\n","#                                      f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","#                                      axis=1).values\n","\n","#     top_per_query = 20\n","\n","#     top_indices_array = []\n","#     top_values_array = []\n","#     for idx in tqdm(range(0, len(corpus_df_valid))):\n","#         all_results = search_engine.perform_search(corpus_df_valid[idx])\n","#         # temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n","#         top_results = all_results[:top_per_query]\n","#         chunk_top_indices = np.array([int(x['file_path']) for x in top_results])\n","#         chunk_top_values = np.array([result.score for result in top_results])\n","#         # chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n","\n","#         top_indices_array.append(chunk_top_indices)\n","#         top_values_array.append(chunk_top_values)\n","\n","#     merged_top_scores = top_values_array\n","#     articles_indices = top_indices_array\n","    \n","#     return articles_indices, merged_top_scores\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# from whoosh.analysis import *\n","# from nltk.stem import *\n","# import nltk\n","# from IR_improved.IR_Q4_1_3 import CustomFilter\n","# nltk.data.path.append('./nltk_data')\n","# analyzer = RegexTokenizer() | StopFilter(stop_words) | LowercaseFilter() | CustomFilter(WordNetLemmatizer().lemmatize, 'v') | CustomFilter(LancasterStemmer().stem)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["'what is the name of the mechanism for plant to absorb sunlight'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# WordNetLemmatizer().lemmatize('what is the name of the mechanism for plant to absorb sunlight')"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[{"data":{"text/plain":["[Token(positions=False, chars=False, stopped=False, boost=1.0, removestops=True, mode='', text='shift'),\n"," Token(positions=False, chars=False, stopped=False, boost=1.0, removestops=True, mode='', text='shift')]"]},"execution_count":189,"metadata":{},"output_type":"execute_result"}],"source":["# list(analyzer(value=u('Red Shift')))"]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[],"source":["# from nltk.stem import WordNetLemmatizer, LancasterStemmer\n","# nltk.data.path.append('./nltk_data')\n","# def nltk_preprocessor(x):\n","#     lemmatizer = WordNetLemmatizer()\n","#     stemmer = LancasterStemmer()\n","#     return ' '.join([stemmer.stem(lemmatizer.lemmatize(word, 'v')) for word in x.split()])"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T20:49:57.126161Z","iopub.status.busy":"2023-10-04T20:49:57.125781Z","iopub.status.idle":"2023-10-04T20:49:57.151999Z","shell.execute_reply":"2023-10-04T20:49:57.150975Z","shell.execute_reply.started":"2023-10-04T20:49:57.126121Z"},"trusted":true},"outputs":[],"source":["# üìÑ Define the function SplitList to split a list into chunks of a specified size.\n","\n","def SplitList(mylist, chunk_size):\n","    return [mylist[offs:offs+chunk_size] for offs in range(0, len(mylist), chunk_size)]\n","\n","# üìÑ Define the function get_relevant_documents_parsed to retrieve relevant documents for OpenBookQA.\n","def get_relevant_documents_parsed(df_valid):\n","    df_chunk_size = 600\n","    \n","    # Load the \"all-paraphs-parsed-expanded\" dataset from disk.\n","    paraphs_parsed_dataset = load_from_disk(\"../input/all-paraphs-parsed-expanded\")\n","    \n","    # Process and modify the text data for retrieval.\n","    modified_texts = paraphs_parsed_dataset.map(lambda example:\n","                                             {'temp_text':\n","                                              f\"{example['title']} {example['section']} {example['text']}\".replace('\\n', \" \").replace(\"'\", \"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    \n","    # Loop through the validation data in chunks.\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        # Perform retrieval and store the results.\n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array = np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    \n","    # Flatten the retrieved articles data.\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         paraphs_parsed_dataset[idx.item()][\"title\"],\n","                         paraphs_parsed_dataset[idx.item()][\"text\"],\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    \n","    # Split the flattened data into chunks.\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","\n","# üìÑ Define the function get_relevant_documents for retrieving relevant documents.\n","def get_relevant_documents(df_valid):\n","\n","    df_chunk_size = 800\n","    \n","    # Load the \"stem-wiki-cohere-no-emb\" dataset from disk.\n","    dataset_name = \"../input/stem-wiki-cohere-no-emb\"\n","    cohere_dataset_filtered = load_from_disk(f\"./{dataset_name}\")\n","    \n","    # Process and modify the text data for retrieval.\n","    modified_texts = cohere_dataset_filtered.map(lambda example:\n","                                             {'temp_text':\n","                                              unicodedata.normalize(\"NFKD\", f\"{example['title']} {example['text']}\").replace('\"', \"\")},\n","                                             num_proc=2)[\"temp_text\"]\n","    \n","    all_articles_indices = []\n","    all_articles_values = []\n","    \n","    # Loop through the validation data in chunks.\n","    for idx in tqdm(range(0, df_valid.shape[0], df_chunk_size)):\n","        df_valid_ = df_valid.iloc[idx: idx+df_chunk_size]\n","    \n","        # Perform retrieval and store the results.\n","        articles_indices, merged_top_scores = retrieval(df_valid_, modified_texts)\n","   \n","        all_articles_indices.append(articles_indices)\n","        all_articles_values.append(merged_top_scores)\n","        \n","    article_indices_array = np.concatenate(all_articles_indices, axis=0)\n","    articles_values_array = np.concatenate(all_articles_values, axis=0).reshape(-1)\n","    \n","    top_per_query = article_indices_array.shape[1]\n","    \n","    # Flatten the retrieved articles data.\n","    articles_flatten = [(\n","                         articles_values_array[index],\n","                         cohere_dataset_filtered[idx.item()][\"title\"],\n","                         unicodedata.normalize(\"NFKD\", cohere_dataset_filtered[idx.item()][\"text\"]),\n","                        )\n","                        for index,idx in enumerate(article_indices_array.reshape(-1))]\n","    \n","    # Split the flattened data into chunks.\n","    retrieved_articles = SplitList(articles_flatten, top_per_query)\n","    return retrieved_articles\n","\n","# üìÑ Define the retrieval function to perform document retrieval.\n","\n","def retrieval(df_valid, modified_texts, vectorizer=TfidfVectorizer):\n","    \n","    corpus_df_valid = df_valid.apply(lambda row:\n","                                     f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","                                     axis=1).values\n","    transformer_corpus = df_valid.apply(lambda row:\n","                                        f'{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n","                                     axis=1).values\n","    \n","    # Create and fit the TF-IDF vectorizer.\n","    vectorizer1 = vectorizer(ngram_range=(1,2),\n","                            token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                            stop_words=stop_words)\n","\n","    vectorizer1.fit(corpus_df_valid)\n","    vocab_df_valid = vectorizer1.get_feature_names_out()\n","    \n","    vectorizer = vectorizer(ngram_range=(1,2),\n","                            token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n","                            stop_words=stop_words,\n","                            vocabulary=vocab_df_valid)\n","\n","    vectorizer.fit(modified_texts[:500000])\n","    corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n","    \n","    print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")\n","\n","    chunk_size = 100000\n","    top_per_chunk = 10\n","    top_per_query = 10\n","\n","    # top_per_chunk = 20\n","    # top_per_query = 20\n","\n","    all_chunk_top_indices = []\n","    all_chunk_top_values = []\n","\n","    for idx in tqdm(range(0, len(modified_texts), chunk_size)):\n","        wiki_vectors = vectorizer.transform(modified_texts[idx: idx+chunk_size])\n","        temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n","        chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n","        chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n","\n","        all_chunk_top_indices.append(chunk_top_indices + idx)\n","        all_chunk_top_values.append(chunk_top_values)\n","\n","    top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n","    top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n","    \n","    merged_top_scores = np.sort(top_values_array, axis=1)[:,-top_per_query:]\n","    merged_top_indices = top_values_array.argsort(axis=1)[:,-top_per_query:]\n","    articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]\n","\n","\n","    for idx, (top_doc_id, query) in enumerate(zip(articles_indices, transformer_corpus)): \n","        docs = [modified_texts[i] for i in top_doc_id]\n","        q_emb = sentModel.encode(query, convert_to_tensor=True, device='cuda', normalize_embeddings=True, )\n","        doc_emb = sentModel.encode(docs, convert_to_tensor=True, device='cuda', normalize_embeddings=True)\n","        scores = q_emb @ doc_emb.T\n","        top_idx = scores.argsort(descending=False).cpu().numpy()\n","        merged_top_scores[idx] = scores[top_idx].cpu().numpy()\n","        articles_indices[idx, :] = articles_indices[idx, top_idx] \n","\n","    return articles_indices, merged_top_scores\n","\n","from functools import partial\n","# retrieval = partial(retrieval, vectorizer=partial(BM25, k1=1.6, b=0.75))\n","\n","# i used this a bit differently than what it was originally written for\n","def prepare_answering_input(\n","    example,  # example that contains, context, question, and options\n","    tokenizer,  # longformer_tokenizer\n","    # max_length=3072,\n","    max_length=4096,\n","\n","):\n","    context = example[\"context\"].replace(\"\\n\", \" \").strip()\n","    question = example[\"prompt\"].replace(\"\\n\", \" \").strip()\n","    options = [example[option].replace(\"\\n\", \" \").strip() for option in \"ABCDE\"]\n","    c_5 = [context] * len(options)\n","    q_plus_o = [\n","        \" \" + tokenizer.bos_token + \" \" + question + \" \" + option for option in options\n","    ]\n","    # try:\n","    tokenized_example = tokenizer(\n","        c_5,\n","        q_plus_o,\n","        truncation=\"only_first\",\n","        max_length=max_length,\n","    )\n","    # except:\n","    #     tokenized_example = tokenizer(\n","    #         c_5,\n","    #         q_plus_o,\n","    #         # truncation=\"only_first\",\n","    #         max_length=max_length,\n","    #     )\n","    tokenized_example[\"label\"] = option_to_index[example[\"answer\"].strip()]\n","    return tokenized_example\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Quasielastic neutron scattering The term quasielastic scattering was originally coined in nuclear physics. It was applied to thermal neutron scattering since the early 1960s, notably in an article by Leon van Hove and in a highly cited one by Pierre Gilles de Gennes.\n","Neutron spin echo Many inelastic studies that use normal time-of-flight (TOF) or backscattering spectrometers rely on the huge incoherent neutron scattering\n","Neutron scattering Neutron scattering is practiced at research reactors and spallation neutron sources that provide neutron radiation of varying intensities. Neutron diffraction (elastic scattering) techniques are used for analyzing structures; where inelastic neutron scattering is used in studying atomic vibrations and other excitations.\n","Small-angle neutron scattering Small-angle neutron scattering (SANS) is an experimental technique that uses elastic neutron scattering at small scattering angles to investigate the structure of various substances at a mesoscopic scale of about 1‚Äì100 nm.\n","Small-angle neutron scattering Small angle neutron scattering is in many respects very similar to small-angle X-ray scattering (SAXS); both techniques are jointly referred to as small-angle scattering (SAS). Advantages of SANS over SAXS are its sensitivity to light elements, the possibility of isotope labelling, and the strong scattering by magnetic moments.\n","Scattering amplitude The nuclear neutron scattering process involves the coherent neutron scattering length, often described by .\n","Polymer scattering The ratio formula_25 will determine the available angular spectrum of this regime. To see this one may consider the case of elastic scattering (even approximately elastic ). If the scattering angle is formula_26, we may express formula_27 as:\n","Debye‚ÄìWaller factor The Debye‚ÄìWaller factor (DWF), named after Peter Debye and Ivar Waller, is used in condensed matter physics to describe the attenuation of x-ray scattering or coherent neutron scattering caused by thermal motion. It is also called the B factor, atomic B factor, or temperature factor. Often, Debye‚ÄìWaller factor is used as a generic term that comprises the Lamb‚ÄìMoÃàssbauer factor of incoherent neutron scattering and MoÃàssbauer spectroscopy.\n","Lamb‚ÄìMoÃàssbauer factor Singwi and SjoÃàlander (1960) pointed out the close relation to incoherent neutron scattering. With the invention of backscattering spectrometers, it became possible to measure the Lamb‚ÄìMoÃàssbauer factor as a function of the wavenumber (whereas MoÃàssbauer spectroscopy operates at a fixed wavenumber). Subsequently, the term elastic incoherent structure factor became more frequent.\n","Lamb‚ÄìMoÃàssbauer factor In physics, the Lamb‚ÄìMoÃàssbauer factor (LMF, after Willis Lamb and Rudolf MoÃàssbauer) or elastic incoherent structure factor (EISF) is the ratio of elastic to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in MoÃàssbauer spectroscopy. The corresponding factor for coherent neutron or X-ray scattering is the Debye‚ÄìWaller factor; often, that term is used in a more generic way to include the incoherent case as well.\n","\n","Neutron scattering Neutron scattering is practiced at research reactors and spallation neutron sources that provide neutron radiation of varying intensities. Neutron diffraction (elastic scattering) techniques are used for analyzing structures; where inelastic neutron scattering is used in studying atomic vibrations and other excitations.\n","Small-angle neutron scattering Small angle neutron scattering is in many respects very similar to small-angle X-ray scattering (SAXS); both techniques are jointly referred to as small-angle scattering (SAS). Advantages of SANS over SAXS are its sensitivity to light elements, the possibility of isotope labelling, and the strong scattering by magnetic moments.\n","Lamb‚ÄìMoÃàssbauer factor Singwi and SjoÃàlander (1960) pointed out the close relation to incoherent neutron scattering. With the invention of backscattering spectrometers, it became possible to measure the Lamb‚ÄìMoÃàssbauer factor as a function of the wavenumber (whereas MoÃàssbauer spectroscopy operates at a fixed wavenumber). Subsequently, the term elastic incoherent structure factor became more frequent.\n","Neutron spin echo Many inelastic studies that use normal time-of-flight (TOF) or backscattering spectrometers rely on the huge incoherent neutron scattering\n","Polymer scattering The ratio formula_25 will determine the available angular spectrum of this regime. To see this one may consider the case of elastic scattering (even approximately elastic ). If the scattering angle is formula_26, we may express formula_27 as:\n","Quasielastic neutron scattering The term quasielastic scattering was originally coined in nuclear physics. It was applied to thermal neutron scattering since the early 1960s, notably in an article by Leon van Hove and in a highly cited one by Pierre Gilles de Gennes.\n","Small-angle neutron scattering Small-angle neutron scattering (SANS) is an experimental technique that uses elastic neutron scattering at small scattering angles to investigate the structure of various substances at a mesoscopic scale of about 1‚Äì100 nm.\n","Scattering amplitude The nuclear neutron scattering process involves the coherent neutron scattering length, often described by .\n","Debye‚ÄìWaller factor The Debye‚ÄìWaller factor (DWF), named after Peter Debye and Ivar Waller, is used in condensed matter physics to describe the attenuation of x-ray scattering or coherent neutron scattering caused by thermal motion. It is also called the B factor, atomic B factor, or temperature factor. Often, Debye‚ÄìWaller factor is used as a generic term that comprises the Lamb‚ÄìMoÃàssbauer factor of incoherent neutron scattering and MoÃàssbauer spectroscopy.\n","Lamb‚ÄìMoÃàssbauer factor In physics, the Lamb‚ÄìMoÃàssbauer factor (LMF, after Willis Lamb and Rudolf MoÃàssbauer) or elastic incoherent structure factor (EISF) is the ratio of elastic to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in MoÃàssbauer spectroscopy. The corresponding factor for coherent neutron or X-ray scattering is the Debye‚ÄìWaller factor; often, that term is used in a more generic way to include the incoherent case as well.\n"]},{"data":{"text/plain":["'What is the Lamb-M√∂ssbauer factor in physics?\\nThe ratio of elastic to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in M√∂ssbauer spectroscopy.\\nThe ratio of elastic to total coherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in M√∂ssbauer spectroscopy.\\nThe ratio of elastic to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in X-ray scattering.\\nThe ratio of coherent to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in X-ray scattering.\\nThe ratio of coherent to total incoherent neutron scattering, or the ratio of recoil-free to total nuclear resonant absorption in M√∂ssbauer spectroscopy.'"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# qid = 20\n","# [print(modified_texts[i]) for i  in new_articles_indices[qid]]\n","# print()\n","# [print(modified_texts[i]) for i  in articles_indices[qid]]\n","# transformer_corpus[qid]"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T20:49:58.338961Z","iopub.status.busy":"2023-10-04T20:49:58.338093Z","iopub.status.idle":"2023-10-04T20:49:58.363755Z","shell.execute_reply":"2023-10-04T20:49:58.362935Z","shell.execute_reply.started":"2023-10-04T20:49:58.338929Z"},"trusted":true},"outputs":[],"source":["# üìÑ Read the test data from the CSV file \"test.csv\" into a DataFrame named \"df_valid\".\n","# df_valid = pd.read_csv(\"../input/kaggle-llm-science-exam/test.csv\")\n","df_valid = pd.read_csv(\"../input/kaggle-llm-science-exam/train.csv\")\n","df_valid = pd.read_csv(\"../input/99k-context/valid_500_with_context2.csv\")\n","IS_TESTING = True\n","if len(df_valid) == 200: \n","  IS_TESTING = False\n","IS_TESTING = True\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-10-04T20:49:58.365849Z","iopub.status.busy":"2023-10-04T20:49:58.365218Z","iopub.status.idle":"2023-10-04T20:57:34.698629Z","shell.execute_reply":"2023-10-04T20:57:34.697557Z","shell.execute_reply.started":"2023-10-04T20:49:58.365818Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1957501dc0794b0b9d920454dab52ae2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["length of vectorizer vocab is 11174\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c705e8a366a749b4a794d2b8e20cd176","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b4bc01f61fc4a01bcf3e0d9bfea6f2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["length of vectorizer vocab is 11174\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b88e84c95cf4430a935528215e2d235","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/28 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# üìÑ Retrieve relevant documents for the test data using the \"get_relevant_documents_parsed\" function.\n","SIM_MODEL = '../input/sentence-transformers-222/all-MiniLM-L6-v2'\n","from sentence_transformers import SentenceTransformer\n","sentModel = SentenceTransformer(SIM_MODEL).cuda().eval()\n","\n","retrieved_articles_parsed = get_relevant_documents_parsed(df_valid)\n","\n","# ‚ôªÔ∏è Perform garbage collection to free up memory.\n","gc.collect()\n","\n","# üìÑ Retrieve relevant documents for the test data using the \"get_relevant_documents\" function.\n","retrieved_articles = get_relevant_documents(df_valid)\n","\n","# ‚ôªÔ∏è Perform garbage collection to free up memory.\n","gc.collect()\n","\n","del sentModel\n","gc.collect()\n","torch.cuda.empty_cache()  \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Models"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForMultipleChoice\n","from peft import LoraConfig, TaskType, get_peft_model\n","# tokenizer = AutoTokenizer.from_pretrained(\"../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350\")\n","# model = AutoModelForMultipleChoice.from_pretrained(\"../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350\").cuda()\n","\n","# checkpoint_path = '/kaggle/input/jason-trained-models-v3-512/checkpoint-344/checkpoint-344'\n","# checkpoint_path = f'../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350'\n","# checkpoint_path = f'../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-344'\n","\n","models_dict = {\n","  'deberta_16_512_v2': {\n","    'checkpoint_path': f'../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350',\n","    'weight': 0.2,\n","  },\n","  'deberta_18_512_v2': {\n","    'checkpoint_path': f'../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550',\n","    'weight': 0.6,\n","  },\n","  # 'reward_deberta_16_512_v2': {\n","  #   'checkpoint_path': f'../working/reward-model-deberta-v3-large-v2_checkpoints/16_512_v4/checkpoint-350',\n","  #   'weight': 0.3,\n","  # },\n","  # 'longformer': {\n","  #   'checkpoint_path': '../input/longformer_qa_model',\n","  #   'weight': 0.2,\n","  # },\n","  # 'deberta_new':{\n","  #   'checkpoint_path': '../working_new/deberta-v3-large_checkpoints/18_512_new/checkpoint-394',\n","  #   'weight': 0.4, # with 0.6 deberta_18_512_v2 985\n","  # },\n","  # 'deberta_new_1024':{\n","  #   'checkpoint_path': '../working_new/deberta_new_18_1024_checkpoint-200',\n","  #   'weight': 0.4, # with 0.6 deberta_18_512_v2 985\n","  # },\n","  'deberta_60k_1024':{\n","    'checkpoint_path': '../working_new/checkpoint-240',\n","    'weight': 0.4, # with 0.6 deberta_18_512_v2 985\n","  },\n","  'deberta_60k_1024_2':{\n","    'checkpoint_path': '../working_new/checkpoint-348',\n","    'weight': 0.4, # with 0.6 deberta_18_512_v2 985\n","  },\n","    'deberta_60k_786_3':{\n","    'checkpoint_path': '../working_new/checkpoint-344',\n","    'weight': 0.4, # with 0.6 deberta_18_512_v2 985\n","  },\n","\n","}\n","\n","# checkpoint_path = f'../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550'\n","\n","def load_model(checkpoint_path, use_peft=True):\n","  if use_peft:\n","    peft_config = LoraConfig.from_pretrained(checkpoint_path, torch_dtype=torch.float16)\n","    model_weights = f'{checkpoint_path}/torch_model'\n","    model = AutoModelForMultipleChoice.from_pretrained(model_weights, \n","                                                       device_map='cuda:0', \n","                                                       torch_dtype=torch.float16)\n","    tokenizer_weights = checkpoint_path\n","    tokenizer = AutoTokenizer.from_pretrained(tokenizer_weights)\n","    model = get_peft_model(model, peft_config)\n","    checkpoint = torch.load(f'{model_weights}/pytorch_model.bin')\n","    model.base_model.model.load_state_dict(checkpoint)\n","  else:\n","    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n","    model = AutoModelForMultipleChoice.from_pretrained(checkpoint_path, \n","                                                       device_map='cuda:0',\n","                                                       torch_dtype=torch.float16)\n","\n","  model.eval().cuda().half()\n","  print('model loaded')\n","  return model, tokenizer\n"]},{"cell_type":"markdown","metadata":{},"source":["## Run inference"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["from util_openbook import DataCollatorForMultipleChoice\n","from torch.utils.data import DataLoader\n","from datasets import Dataset\n","import pickle\n","\n","\n","if 'answer' not in df_valid.columns:\n","    df_valid['answer'] = 'A'\n"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2023-08-11T17:11:57.829758Z","iopub.status.busy":"2023-08-11T17:11:57.829337Z","iopub.status.idle":"2023-08-11T17:13:53.780911Z","shell.execute_reply":"2023-08-11T17:13:53.779904Z","shell.execute_reply.started":"2023-08-11T17:11:57.829727Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.13.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.7.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.2.output.dense.lora_B.default.weight', 'deberta.encoder.layer.0.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.15.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.22.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.output.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'pooler.original_module.dense.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.23.output.dense.lora_B.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.12.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.11.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.output.dense.lora_B.default.weight', 'deberta.encoder.layer.11.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.output.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.output.dense.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.5.output.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.3.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.19.output.dense.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'pooler.original_module.dense.lora_A.default.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.output.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.17.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.2.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.15.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.14.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.22.output.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_B.default.weight', 'deberta.encoder.layer.1.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.12.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.output.dense.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.10.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.output.dense.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.17.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.6.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_B.default.weight', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.9.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eddf1129190c483c9a0f567d60a0dc5b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30063f10ec5e47519bb197bce7767305","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-240/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-240/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7fd52f79ab740b8ace9834f5852238f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-348/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-348/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26c40121ff1d4f8d881d6bcb86b1dc35","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-344/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-344/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcd47aba08104b74b7d5468b59d1daf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["# üìä Initialize empty lists to store predictions and submit IDs.\n","\n","if IS_TESTING:\n","    # üîÑ Loop through the test data.\n","    for model_name in models_dict:\n","        predictions = []\n","        submit_ids = []\n","        if 'deberta' in model_name:\n","            model, tokenizer = load_model(models_dict[model_name]['checkpoint_path'], use_peft=True)\n","        else:\n","            model, tokenizer = load_model(models_dict[model_name]['checkpoint_path'], use_peft=False)\n","\n","        models_dict[model_name]['prob'] = []\n","        data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n","        for index in tqdm(range(df_valid.shape[0])):\n","            \n","            columns = df_valid.iloc[index].values\n","            submit_ids.append(columns[0])\n","            question = columns[1]\n","            options = [columns[2], columns[3], columns[4], columns[5], columns[6]]\n","            \n","            answer = columns[7] if len(columns) == 8 else 'A'\n","            # üìú Prepare two different contexts using retrieved articles.\n","            context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n","            context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n","            \n","            # üìö Prepare input for answering questions using the tokenizer.\n","            # inputs1 = prepare_answering_input(\n","            #     tokenizer=tokenizer, question=question,\n","            #     options=options, context=context1,\n","            # )\n","            # inputs2 = prepare_answering_input(\n","            #     tokenizer=tokenizer, question=question,\n","            #     options=options, context=context2,\n","            # )\n","            example1 = {\n","                \"context\": context1,\n","                \"prompt\": question,\n","                \"answer\": answer,\n","                **{ch: opt for ch, opt in zip(list(\"ABCDE\"), options)},\n","            }\n","            example2 = {\n","                \"context\": context2,\n","                \"prompt\": question,\n","                \"answer\": answer,\n","                **{ch: opt for ch, opt in zip(list(\"ABCDE\"), options)},\n","            }\n","            inputs1 = prepare_answering_input(\n","                example = example1,\n","                tokenizer=tokenizer,\n","            )\n","            # inputs1['label'] = 0\n","            inputs1 = data_collator([inputs1])\n","            inputs2 = prepare_answering_input(\n","                example = example2,\n","                tokenizer=tokenizer,\n","            )\n","            inputs2 = data_collator([inputs2])\n","\n","            # üöÄ Make predictions using the Longformer model.\n","            with torch.no_grad():\n","                for k in inputs1.keys():\n","                    inputs1[k] = inputs1[k].cuda()\n","                outputs1 = model(**inputs1)    \n","                losses1 = -outputs1.logits[0].detach().cpu().numpy()\n","                probability1 = torch.softmax(torch.tensor(-losses1).float(), dim=-1)\n","                # del inputs1, losses1, outputs1\n","                # gc.collect()\n","\n","            with torch.no_grad():\n","                for k in inputs2.keys():\n","                    inputs2[k] = inputs2[k].cuda()\n","                outputs2 = model(**inputs2)\n","                losses2 = -outputs2.logits[0].detach().cpu().numpy()\n","                probability2 = torch.softmax(torch.tensor(-losses2).float(), dim=-1)\n","                # del inputs2, losses2, outputs2\n","                # gc.collect()\n","                \n","            # üßæ Calculate the combined probability.\n","            # probability_ = (probability1 + probability2) / 2 # 0.87, 96\n","            probability_ = (probability1**2 + probability2**2) / 2 # 0.87, 96\n","\n","            # probability_ = probability1 * 0.4 + probability2 * 0.6 # 0.89, 95\n","\n","            models_dict[model_name]['prob'].append(probability_)\n","\n","\n","            # predict = np.array(list(\"ABCDE\"))[np.argsort(probability_)][-3:].tolist()[::-1]\n","            # predictions.append(predict)\n","            \n","\n","        # üìÑ Combine the predictions into a single string for submission.\n","        # predictions = [\" \".join(i) for i in predictions]\n","        with open(f'{model_name}_prob.pkl', 'wb') as f:\n","            pickle.dump(models_dict[model_name]['prob'], f)\n","        del models_dict[model_name]['prob']\n","        del model, tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.13.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.7.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.2.output.dense.lora_B.default.weight', 'deberta.encoder.layer.0.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.15.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.22.output.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.output.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'pooler.original_module.dense.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.23.output.dense.lora_B.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.12.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.11.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.output.dense.lora_B.default.weight', 'deberta.encoder.layer.11.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.output.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.output.dense.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.5.output.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.3.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.19.output.dense.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'pooler.original_module.dense.lora_A.default.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.output.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.17.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.2.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.15.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.14.output.dense.lora_B.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.22.output.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_B.default.weight', 'deberta.encoder.layer.1.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.0.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.12.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.8.output.dense.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.10.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.output.dense.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.17.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.6.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_B.default.weight', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.9.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working/deberta-v3-large_checkpoints/16_512_v2/checkpoint-350/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ce52ff0abdf4813a49e3c2b9e098f84","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working/deberta-v3-large_checkpoints/checkpoints_18_512/checkpoint-550/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66be10a40ebe4982a3bc8b8416e24871","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-240/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-240/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"545d79e6db7640d78080c33c0a08c742","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-348/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-348/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"339c2eecfbf8407fa57585fea41b1f0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","Some weights of the model checkpoint at ../working_new/checkpoint-344/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.bias', 'pooler.original_module.dense.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight']\n","- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at ../working_new/checkpoint-344/torch_model and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7af310b31db04b8b831d72dabb8b6a8e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["# üìä Initialize empty lists to store predictions and submit IDs.\n","\n","if IS_TESTING:\n","    # üîÑ Loop through the test data.\n","    for model_name in models_dict:\n","        predictions = []\n","        submit_ids = []\n","        if 'deberta' in model_name:\n","            model, tokenizer = load_model(models_dict[model_name]['checkpoint_path'], use_peft=True)\n","        else:\n","            model, tokenizer = load_model(models_dict[model_name]['checkpoint_path'], use_peft=False)\n","\n","        models_dict[model_name]['prob'] = []\n","        data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n","        for index in tqdm(range(df_valid.shape[0])):\n","            \n","            columns = df_valid.iloc[index].values\n","            submit_ids.append(columns[0])\n","            question = columns[0]\n","            options = [columns[2], columns[3],columns[4], columns[5], columns[6]]\n","            \n","            answer = columns[7]\n","            # üìú Prepare two different contexts using retrieved articles.\n","            # context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n","            # context2 = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\"\n","            context1 = columns[1]\n","            # üìö Prepare input for answering questions using the tokenizer.\n","            # inputs1 = prepare_answering_input(\n","            #     tokenizer=tokenizer, question=question,\n","            #     options=options, context=context1,\n","            # )\n","            # inputs2 = prepare_answering_input(\n","            #     tokenizer=tokenizer, question=question,\n","            #     options=options, context=context2,\n","            # )\n","            example1 = {\n","                \"context\": context1,\n","                \"prompt\": question,\n","                \"answer\": answer,\n","                **{ch: opt for ch, opt in zip(list(\"ABCDE\"), options)},\n","            }\n","\n","            inputs1 = prepare_answering_input(\n","                example = example1,\n","                tokenizer=tokenizer,\n","            )\n","            # inputs1['label'] = 0\n","            inputs1 = data_collator([inputs1])\n","\n","\n"," \n","            with torch.no_grad():\n","                for k in inputs1.keys():\n","                    inputs1[k] = inputs1[k].cuda()\n","                outputs1 = model(**inputs1)\n","                losses1 = -outputs1.logits[0].detach().cpu().numpy()\n","                probability1 = torch.softmax(torch.tensor(-losses1).float(), dim=-1)\n","                \n","            # üßæ Calculate the combined probability.\n","            # probability_ = (probability1 + probability2) / 2 # 0.87, 96\n","            probability_ = probability1\n","\n","            # probability_ = probability1 * 0.4 + probability2 * 0.6 # 0.89, 95\n","\n","            models_dict[model_name]['prob'].append(probability_)\n","\n","\n","            # predict = np.array(list(\"ABCDE\"))[np.argsort(probability_)][-3:].tolist()[::-1]\n","            # predictions.append(predict)\n","            \n","\n","        # üìÑ Combine the predictions into a single string for submission.\n","        # predictions = [\" \".join(i) for i in predictions]\n","        with open(f'{model_name}_prob.pkl', 'wb') as f:\n","            pickle.dump(models_dict[model_name]['prob'], f)\n","        del models_dict[model_name]['prob']\n","        del model, tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["deberta_16_512_v2 loaded\n","deberta_18_512_v2 loaded\n","deberta_60k_1024 loaded\n","deberta_60k_1024_2 loaded\n","deberta_60k_786_3 loaded\n"]}],"source":["import pickle\n","for model_name in models_dict:\n","  with open(f'{model_name}_prob.pkl', 'rb') as f:\n","      models_dict[model_name]['prob'] = pickle.load(f)\n","  print(f'{model_name} loaded')"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","    \"deberta_16_512_v2\": {\n","        \"weight\": 0.2\n","    },\n","    \"deberta_18_512_v2\": {\n","        \"weight\": 0.6\n","    },\n","    \"deberta_60k_1024\": {\n","        \"weight\": 0.4\n","    },\n","    \"deberta_60k_1024_2\": {\n","        \"weight\": 0.4\n","    },\n","    \"deberta_60k_786_3\": {\n","        \"weight\": 0.4\n","    }\n","}\n"]}],"source":["weights_dict = {n:{'weight':models_dict[n]['weight']} for n in models_dict}\n","import json\n","weights_dict =json.dumps(weights_dict,  indent=4)\n","print(weights_dict)"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV MAP@3 = 0.99\n"]}],"source":["from collections import OrderedDict\n","weights_dict = {\n","    \"deberta_16_512_v2\": {\n","        \"weight\": 0\n","    },\n","    \"deberta_18_512_v2\": {\n","        \"weight\": 0\n","    },\n","    \"deberta_60k_1024\": {\n","        \"weight\": 0\n","    },\n","    \"deberta_60k_1024_2\": {\n","        \"weight\": 0.\n","    },\n","    \"deberta_60k_786_3\": {\n","        \"weight\": 1.\n","    }\n","}\n","weights_dict = OrderedDict(weights_dict)\n","\n","for model_name in weights_dict:\n","  models_dict[model_name]['weight'] = weights_dict[model_name]['weight']\n","\n","power = 1\n","\n","final_probs = None\n","for model_name in weights_dict:\n","    prob_array = np.array(models_dict[model_name]['prob'])\n","    if final_probs is None:\n","        final_probs = prob_array **power * models_dict[model_name]['weight']\n","    else:\n","        final_probs += prob_array **power * models_dict[model_name]['weight']\n","\n","final_predictions = []\n","for probability_ in final_probs:\n","    predict = np.array(list(\"ABCDE\"))[np.argsort(probability_)][-3:].tolist()[::-1]\n","    final_predictions.append(' '.join(predict))\n","\n","# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\n","import numpy as np\n","def precision_at_k(r, k):\n","    \"\"\"Precision at k\"\"\"\n","    assert k <= len(r)\n","    assert k != 0\n","    return sum(int(x) for x in r[:k]) / k\n","\n","def MAP_at_k(predictions, true_items, k=3):\n","    \"\"\"Score is mean average precision at k\"\"\"\n","    U = len(predictions)\n","    map_at_3 = 0.0\n","    for u in range(U):\n","        user_preds = predictions[u].split()\n","        user_true = true_items[u]\n","        user_results = [1 if item == user_true else 0 for item in user_preds]\n","        for i in range(min(len(user_preds), k)):\n","            map_at_3 += precision_at_k(user_results, i+1) * user_results[i]\n","    return map_at_3 / U\n","\n","m = MAP_at_k(final_predictions, df_valid.answer.values, k=3)\n","print( 'CV MAP@3 =', m)"]},{"cell_type":"markdown","metadata":{},"source":["### Try weights\n"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d27d8f14193f4208b25402db5857b8bb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/220 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[0.985, 0.9925, 0.9925]\n","21\n"]}],"source":["from itertools import combinations\n","n = 3\n","all_combs = combinations(range(12), n)\n","comb_results = {}\n","highest_m = []\n","\n","\n","from collections import OrderedDict\n","for comb in tqdm(list(all_combs)):\n","  new_comb = list(comb).copy()\n","  for _ in range(n):\n","    new_comb = new_comb[1:] + new_comb[:1]\n","    # i, j, k, l  = new_comb\n","    for nc,k in zip(new_comb,weights_dict.keys()):\n","        weights_dict[k]['weight'] = nc\n","    for model_name in weights_dict:\n","        models_dict[model_name]['weight'] = weights_dict[model_name]['weight']\n","    final_probs = None\n","    for model_name in models_dict:\n","        prob_array = np.array(models_dict[model_name]['prob'])\n","        if final_probs is None:\n","            final_probs = prob_array**power * models_dict[model_name]['weight']\n","        else:\n","            final_probs += prob_array**power * models_dict[model_name]['weight']\n","\n","    final_predictions = []\n","    for probability_ in final_probs:\n","        predict = np.array(list(\"ABCDE\"))[np.argsort(probability_)][-3:].tolist()[::-1]\n","        final_predictions.append(' '.join(predict))\n","    \n","    m = []\n","    for i in range(0, 3):\n","        m.append(MAP_at_k(final_predictions, df_valid.answer.values, i+1))\n","    comb_results[' '.join([str(_) for _ in new_comb])] = sum(m)\n","    if sum(m)>=sum(highest_m):\n","        # print(new_comb, m)\n","        highest_m = m\n","        \n","print(highest_m)\n","\n","all_comb_mat = []\n","from collections import Counter\n","for comb in comb_results:\n","  if comb_results[comb] == sum(highest_m):\n","    comb_numbers = [int(x) for x in comb.split()]\n","    all_comb_mat.append(comb_numbers)\n","\n","all_comb_mat = np.array(all_comb_mat)\n","print(len(all_comb_mat))"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1, 2, 3, 4, 0],\n","       [0, 1, 2, 3, 4],\n","       [2, 3, 5, 0, 1],\n","       [2, 3, 6, 0, 1],\n","       [2, 3, 7, 0, 1],\n","       [2, 3, 8, 0, 1],\n","       [2, 3, 9, 0, 1],\n","       [1, 2, 4, 5, 0],\n","       [1, 2, 4, 6, 0],\n","       [2, 4, 6, 0, 1],\n","       [1, 2, 4, 7, 0],\n","       [2, 4, 7, 0, 1],\n","       [1, 2, 4, 8, 0],\n","       [2, 4, 8, 0, 1],\n","       [1, 2, 4, 9, 0],\n","       [2, 4, 9, 0, 1],\n","       [1, 2, 5, 6, 0],\n","       [1, 2, 5, 7, 0],\n","       [2, 5, 7, 0, 1],\n","       [1, 2, 5, 8, 0],\n","       [2, 5, 8, 0, 1],\n","       [1, 2, 5, 9, 0],\n","       [2, 5, 9, 0, 1],\n","       [1, 2, 6, 7, 0],\n","       [1, 2, 6, 8, 0],\n","       [2, 6, 8, 0, 1],\n","       [1, 2, 6, 9, 0],\n","       [2, 6, 9, 0, 1],\n","       [1, 2, 7, 8, 0],\n","       [1, 2, 7, 9, 0],\n","       [2, 7, 9, 0, 1],\n","       [1, 2, 8, 9, 0],\n","       [3, 4, 7, 0, 1],\n","       [3, 4, 8, 0, 1],\n","       [3, 4, 9, 0, 1],\n","       [1, 3, 5, 6, 0],\n","       [1, 3, 5, 7, 0],\n","       [1, 3, 5, 8, 0],\n","       [3, 5, 8, 0, 1],\n","       [1, 3, 5, 9, 0],\n","       [3, 5, 9, 0, 1],\n","       [1, 3, 6, 7, 0],\n","       [1, 3, 6, 8, 0],\n","       [1, 3, 6, 9, 0],\n","       [3, 6, 9, 0, 1],\n","       [1, 3, 7, 8, 0],\n","       [1, 3, 7, 9, 0],\n","       [1, 3, 8, 9, 0],\n","       [4, 5, 8, 0, 1],\n","       [4, 5, 9, 0, 1],\n","       [1, 4, 6, 7, 0],\n","       [1, 4, 6, 8, 0],\n","       [1, 4, 6, 9, 0],\n","       [4, 6, 9, 0, 1],\n","       [1, 4, 7, 8, 0],\n","       [1, 4, 7, 9, 0],\n","       [1, 4, 8, 9, 0],\n","       [1, 5, 7, 8, 0],\n","       [1, 5, 7, 9, 0],\n","       [1, 5, 8, 9, 0],\n","       [1, 6, 8, 9, 0],\n","       [3, 4, 7, 0, 2],\n","       [3, 4, 8, 0, 2],\n","       [3, 4, 9, 0, 2],\n","       [2, 3, 5, 6, 0],\n","       [2, 3, 5, 7, 0],\n","       [2, 3, 5, 8, 0],\n","       [3, 5, 8, 0, 2],\n","       [3, 5, 9, 0, 2],\n","       [2, 3, 6, 7, 0],\n","       [2, 3, 6, 8, 0],\n","       [2, 3, 6, 9, 0],\n","       [3, 6, 9, 0, 2],\n","       [2, 3, 7, 8, 0],\n","       [2, 3, 7, 9, 0],\n","       [2, 3, 8, 9, 0],\n","       [0, 2, 4, 5, 6],\n","       [0, 2, 4, 5, 7],\n","       [4, 5, 8, 0, 2],\n","       [0, 2, 4, 5, 8],\n","       [4, 5, 9, 0, 2],\n","       [0, 2, 4, 5, 9],\n","       [2, 4, 6, 7, 0],\n","       [0, 2, 4, 6, 7],\n","       [2, 4, 6, 8, 0],\n","       [0, 2, 4, 6, 8],\n","       [4, 6, 9, 0, 2],\n","       [2, 4, 7, 8, 0],\n","       [2, 4, 7, 9, 0],\n","       [2, 4, 8, 9, 0],\n","       [0, 2, 5, 6, 7],\n","       [0, 2, 5, 6, 8],\n","       [2, 5, 7, 8, 0],\n","       [0, 2, 5, 7, 8],\n","       [2, 5, 8, 9, 0],\n","       [0, 2, 6, 7, 8],\n","       [4, 5, 8, 0, 3],\n","       [4, 5, 9, 0, 3],\n","       [4, 6, 9, 0, 3],\n","       [3, 4, 7, 8, 0],\n","       [3, 4, 7, 9, 0],\n","       [3, 4, 8, 9, 0],\n","       [0, 3, 5, 6, 7],\n","       [0, 3, 5, 6, 8],\n","       [0, 3, 5, 6, 9],\n","       [0, 3, 5, 7, 8],\n","       [0, 3, 5, 7, 9],\n","       [3, 5, 8, 9, 0],\n","       [0, 3, 5, 8, 9],\n","       [0, 3, 6, 7, 8],\n","       [0, 3, 6, 7, 9],\n","       [0, 3, 6, 8, 9],\n","       [0, 3, 7, 8, 9],\n","       [0, 4, 6, 7, 8],\n","       [0, 4, 6, 7, 9],\n","       [0, 4, 6, 8, 9],\n","       [0, 4, 7, 8, 9],\n","       [0, 5, 7, 8, 9],\n","       [3, 4, 7, 1, 2],\n","       [3, 4, 8, 1, 2],\n","       [3, 4, 9, 1, 2],\n","       [2, 3, 5, 6, 1],\n","       [3, 5, 8, 1, 2],\n","       [3, 5, 9, 1, 2],\n","       [2, 3, 6, 7, 1],\n","       [2, 3, 6, 8, 1],\n","       [2, 3, 6, 9, 1],\n","       [3, 6, 9, 1, 2],\n","       [2, 3, 7, 8, 1],\n","       [2, 3, 7, 9, 1],\n","       [2, 3, 8, 9, 1],\n","       [1, 2, 4, 5, 6],\n","       [4, 5, 8, 1, 2],\n","       [4, 5, 9, 1, 2],\n","       [4, 6, 9, 1, 2],\n","       [2, 4, 7, 8, 1],\n","       [2, 4, 7, 9, 1],\n","       [2, 4, 8, 9, 1],\n","       [1, 2, 5, 6, 7],\n","       [2, 5, 8, 9, 1],\n","       [4, 5, 9, 1, 3],\n","       [3, 4, 7, 8, 1],\n","       [3, 4, 7, 9, 1],\n","       [3, 4, 8, 9, 1],\n","       [3, 5, 8, 9, 1],\n","       [1, 3, 6, 7, 8],\n","       [1, 3, 6, 7, 9],\n","       [1, 3, 6, 8, 9],\n","       [1, 3, 7, 8, 9],\n","       [1, 4, 7, 8, 9],\n","       [4, 5, 9, 2, 3],\n","       [3, 4, 7, 8, 2],\n","       [3, 4, 7, 9, 2],\n","       [3, 4, 8, 9, 2],\n","       [3, 5, 8, 9, 2],\n","       [2, 3, 6, 7, 8],\n","       [2, 3, 7, 8, 9]])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["all_comb_mat"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0387f84481ec4327b08d2a75a02c1ca4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a0969cd09f340d1b0a443a2718ea1d0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67caab2eb35b4d668db47cd60b5def82","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import matplotlib.pyplot as plt\n","posting_list = []\n","examined_i = []\n","examined_count = []\n","examined_i_value = []\n","\n","\n","for _ in range(all_comb_mat.shape[-1]):\n","\n","  condition = np.ones(all_comb_mat.shape[0], dtype=bool)\n","  for ei, eival in zip(examined_i, examined_i_value):\n","    condition = condition & (all_comb_mat[:, ei] == eival)\n","  \n","  cur_all_comb_mat = all_comb_mat[condition]\n","  current_highest_i = -1\n","  current_highest_count = 0 \n","  for i in tqdm(range(cur_all_comb_mat.shape[-1])):\n","    if i in examined_i:\n","      continue\n","    plt.title(f'i={i}')\n","    plt.hist(cur_all_comb_mat[:, i])\n","    plt.show()\n","    counts = Counter(cur_all_comb_mat[:, i])\n","    counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n","    if counts[0][1] > current_highest_count:\n","      current_highest_count = counts[0][1]\n","      current_i_value = counts[0][0]\n","      current_highest_i = i\n","\n","  examined_i.append(current_highest_i)\n","  examined_i_value.append(current_i_value)\n","  examined_count.append(current_highest_count)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["[(0, 7, 4), (1, 1, 5), (2, 39, 1)]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["all_list = list(zip(examined_i, examined_count, examined_i_value))\n","all_list = sorted(all_list, key=lambda x: x[0], reverse=False) \n","all_list"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-08-11T17:09:27.495432Z","iopub.status.busy":"2023-08-11T17:09:27.495047Z","iopub.status.idle":"2023-08-11T17:09:27.510631Z","shell.execute_reply":"2023-08-11T17:09:27.509601Z","shell.execute_reply.started":"2023-08-11T17:09:27.495397Z"},"trusted":true},"outputs":[],"source":["# üìä Create a DataFrame with submit IDs and predictions, and save it as a CSV file.\n","pd.DataFrame({'id': submit_ids, 'prediction': predictions}).to_csv('submission.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Explore More! üëÄ\n","Thank you for exploring this notebook! If you found this notebook insightful or if it helped you in any way, I invite you to explore more of my work on my profile.\n","\n","üëâ [Visit my Profile](https://www.kaggle.com/zulqarnainali) üëà\n","\n","## Feedback and Gratitude üôè\n","We value your feedback! Your insights and suggestions are essential for our continuous improvement. If you have any comments, questions, or ideas to share, please don't hesitate to reach out.\n","\n","üì¨ Contact me via email: [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com)\n","\n","I would like to express our heartfelt gratitude for your time and engagement. Your support motivates us to create more valuable content.\n","\n","## Happy coding and best of luck in your data science endeavors! üöÄ\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
