{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How To Train Model for Open Book Q&A Technique - Part 2\nThe notebook you are reading is a fork of Mgoksu's great notebook [here][1]. Mgoksu (@mgoksu) demonstrated how to achieve top public LB=0.807 using Open Book technique. The Open Book method was first presented by JJ (@jjinho) [here][2], then Quangteo (@quangbk) improved RAM usage [here][3], and Anil (@nlztrk) combined with Q&A [here][4]. Radek (@radek1) demonstrated the strength of Q&A [here][5].\n\nIn my previous notebook [here][6] (i.e. Part 1), we demonstrated how to train a model for Open Book. The model was trained using my 60k Kaggle dataset [here][7]. If you enjoy the notebook you are reading, please upvote the dataset too. Thanks!\n\nIn this notebook, we will load the trained model output from my previous notebook. We will infer this model after running the code from Mgoksu's public notebook to use Open Book to seach Wikipedia for context. For each test sample in the hidden dataset, we will append Wikipedia context. Then our trained model will infer the multiple choice answer (using both question and appended Wikipedia context). When predicting the answer, this notebook uses a 50% 50% ensemble of the new Q&A model we trained ensembled with Mgoksu's original model. Here is a diagram showing the Open Book method:\n\n![](https://miro.medium.com/v2/resize:fit:800/format:webp/1*bTGY3fKIgNefQxNsOYpnBw.png)\n\n(image source [here][8])\n\n[1]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model\n[2]: https://www.kaggle.com/code/jjinho/open-book-llm-science-exam\n[3]: https://www.kaggle.com/code/quangbk/open-book-llm-science-exam-reduced-ram-usage\n[4]: https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model\n[5]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training\n[6]: https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model\n[7]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[8]: https://blog.gopenai.com/enrich-llms-with-retrieval-augmented-generation-rag-17b82a96b6f0","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:00:37.324711Z","iopub.execute_input":"2023-09-18T05:00:37.325786Z","iopub.status.idle":"2023-09-18T05:00:37.346607Z","shell.execute_reply.started":"2023-09-18T05:00:37.325745Z","shell.execute_reply":"2023-09-18T05:00:37.345263Z"}}},{"cell_type":"markdown","source":"# OpenBook DeBERTaV3-Large with an updated model\n\nThis work is based on the great [work](https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model) of [nlztrk](https://www.kaggle.com/nlztrk).\n\nI trained a model offline using the dataset I shared [here](https://www.kaggle.com/datasets/mgoksu/llm-science-exam-dataset-w-context). I just added my model to the original notebook. The model is available [here](https://www.kaggle.com/datasets/mgoksu/llm-science-run-context-2).\n\nI also addressed the problem of [CSV Not Found at submission](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/434228) with this notebook by clipping the context like so:\n\n`test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:1500]) + \" #### \" +  test_df[\"prompt\"]`\n\nYou can probably get more than 1500 without getting an OOM.","metadata":{}},{"cell_type":"code","source":"# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":126.809817,"end_time":"2023-08-14T10:09:22.925969","exception":false,"start_time":"2023-08-14T10:07:16.116152","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:07:44.238576Z","iopub.execute_input":"2023-09-19T03:07:44.238954Z","iopub.status.idle":"2023-09-19T03:09:45.188510Z","shell.execute_reply.started":"2023-09-19T03:07:44.238922Z","shell.execute_reply":"2023-09-19T03:09:45.187228Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nProcessing ./sentence-transformers\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126134 sha256=b16fb534b977453600e05a6402b3a3566d0e1d8927d7b87a166298f6c72a9dbf\n  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nProcessing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\nInstalling collected packages: blingfire\nSuccessfully installed blingfire-0.1.8\nProcessing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed transformers-4.31.0\nProcessing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\nInstalling collected packages: peft\nSuccessfully installed peft-0.4.0\nProcessing /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\nInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.3\nProcessing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\nInstalling collected packages: trl\nSuccessfully installed trl-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\nimport os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nfrom dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom torch.utils.data import DataLoader","metadata":{"papermill":{"duration":8.534957,"end_time":"2023-08-14T10:09:31.474781","exception":false,"start_time":"2023-08-14T10:09:22.939824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:09:45.190953Z","iopub.execute_input":"2023-09-19T03:09:45.191627Z","iopub.status.idle":"2023-09-19T03:09:59.125461Z","shell.execute_reply.started":"2023-09-19T03:09:45.191589Z","shell.execute_reply":"2023-09-19T03:09:59.124522Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = 3,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Main helper function to process documents from the EMR.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param document_type: String denoting the document type to be processed\n    :param document_sections: List of sections for a given document type to process\n    :param split_sentences: Flag to determine whether to further split sections into sentences\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Obtains the sections of the imaging reports and returns only the \n    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n    \"\"\"\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = 3,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Split a document into sentences. Can be used with `sectionize_documents`\n    to further split documents into more manageable pieces. Takes in offsets\n    to ensure that after splitting, the sentences can be matched to the\n    location in the original documents.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param offsets: Iterable tuple of the start and end indices\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"papermill":{"duration":0.034054,"end_time":"2023-08-14T10:09:31.574046","exception":false,"start_time":"2023-08-14T10:09:31.539992","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\n# MAX_LENGTH = 384\nMAX_LENGTH = 512\n# BATCH_SIZE = 16\nBATCH_SIZE = 8\nMAX_INPUT =  2048\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)","metadata":{"papermill":{"duration":0.036342,"end_time":"2023-08-14T10:09:31.623595","exception":false,"start_time":"2023-08-14T10:09:31.587253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:20:21.502394Z","iopub.execute_input":"2023-09-19T03:20:21.503110Z","iopub.status.idle":"2023-09-19T03:20:21.629948Z","shell.execute_reply.started":"2023-09-19T03:20:21.503075Z","shell.execute_reply":"2023-09-19T03:20:21.629027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Relevant Title Retrieval","metadata":{}},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\ntrn.head()","metadata":{"papermill":{"duration":0.058533,"end_time":"2023-08-14T10:09:31.695383","exception":false,"start_time":"2023-08-14T10:09:31.63685","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(SIM_MODEL, device='cuda')\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half()","metadata":{"papermill":{"duration":13.282604,"end_time":"2023-08-14T10:09:44.992949","exception":false,"start_time":"2023-08-14T10:09:31.710345","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Faiss contains several methods for similarity search. It assumes that the instances are represented as vectors and are identified by an integer, and that the vectors can be compared with L2 (Euclidean) distances or dot products. Vectors that are similar to a query vector are those that have the lowest L2 distance or the highest dot product with the query vector. It also supports cosine similarity, since this is a dot product on normalized vectors.\n\nSome of the methods, like those based on binary vectors and compact quantization codes, solely use a compressed representation of the vectors and do not require to keep the original vectors. This generally comes at the cost of a less precise search but these methods can scale to billions of vectors in main memory on a single server. Other methods, like HNSW and NSG add an indexing structure on top of the raw vectors to make searching more efficient.\n\nThe GPU implementation can accept input from either CPU or GPU memory. On a server with GPUs, the GPU indexes can be used a drop-in replacement for the CPU indexes (e.g., replace IndexFlatL2 with GpuIndexFlatL2) and copies to/from GPU memory are handled automatically. Results will be faster however if both input and output remain resident on the GPU. Both single and multi-GPU usage is supported.","metadata":{}},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"papermill":{"duration":95.926417,"end_time":"2023-08-14T10:11:20.934445","exception":false,"start_time":"2023-08-14T10:09:45.008028","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n_ = gc.collect()","metadata":{"papermill":{"duration":10.891104,"end_time":"2023-08-14T10:11:31.84869","exception":false,"start_time":"2023-08-14T10:11:20.957586","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the top 3 pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 5)","metadata":{"papermill":{"duration":23.339585,"end_time":"2023-08-14T10:11:55.247556","exception":false,"start_time":"2023-08-14T10:11:31.907971","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.877305,"end_time":"2023-08-14T10:11:56.145444","exception":false,"start_time":"2023-08-14T10:11:55.268139","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Sentences from the Relevant Titles","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n                     columns=['id', 'file'])","metadata":{"papermill":{"duration":5.737408,"end_time":"2023-08-14T10:12:01.897408","exception":false,"start_time":"2023-08-14T10:11:56.16","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n## Save memory - delete df since it is no longer necessary\ndel df\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.799872,"end_time":"2023-08-14T10:12:02.712752","exception":false,"start_time":"2023-08-14T10:12:01.91288","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"papermill":{"duration":303.981049,"end_time":"2023-08-14T10:17:06.710072","exception":false,"start_time":"2023-08-14T10:12:02.729023","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parse documents into sentences\nprocessed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"papermill":{"duration":4.491281,"end_time":"2023-08-14T10:17:11.220342","exception":false,"start_time":"2023-08-14T10:17:06.729061","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get embeddings of the wiki text data\nwiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":25.110593,"end_time":"2023-08-14T10:17:36.348422","exception":false,"start_time":"2023-08-14T10:17:11.237829","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"papermill":{"duration":0.315807,"end_time":"2023-08-14T10:17:36.679867","exception":false,"start_time":"2023-08-14T10:17:36.36406","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Combine all answers\ntrn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n\n\n## Search using the prompt and answers to guide the search\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"papermill":{"duration":0.034767,"end_time":"2023-08-14T10:17:36.730378","exception":false,"start_time":"2023-08-14T10:17:36.695611","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings = question_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":0.431343,"end_time":"2023-08-14T10:17:37.177862","exception":false,"start_time":"2023-08-14T10:17:36.746519","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Matching Prompt-Sentence Pairs","metadata":{}},{"cell_type":"code","source":"## Parameter to determine how many relevant sentences to include\nNUM_SENTENCES_INCLUDE = 20 # 这个也是一个很重要的 factor\n\n## List containing just Context\ncontexts = []\n\nfor r in tqdm(trn.itertuples(), total=len(trn)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts.append(context)","metadata":{"papermill":{"duration":1.609553,"end_time":"2023-08-14T10:17:38.836268","exception":false,"start_time":"2023-08-14T10:17:37.226715","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts","metadata":{"papermill":{"duration":0.024188,"end_time":"2023-08-14T10:17:38.878394","exception":false,"start_time":"2023-08-14T10:17:38.854206","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)","metadata":{"papermill":{"duration":0.050945,"end_time":"2023-08-14T10:17:38.944423","exception":false,"start_time":"2023-08-14T10:17:38.893478","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.015828,"end_time":"2023-08-14T10:17:39.007683","exception":false,"start_time":"2023-08-14T10:17:38.991855","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df = pd.read_csv(\"test_context.csv\")\n\ntest_df.index = list(range(len(test_df)))\ntest_df['id'] = list(range(len(test_df)))\n\n\ntest_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:MAX_INPUT+16]) + \" #### \" +  test_df[\"prompt\"]\n# test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:1750]) + \" #### \" +  test_df[\"prompt\"]\n# test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:2500]) + \" #### \" +  test_df[\"prompt\"]\n\ntest_df['answer'] = 'A'","metadata":{"papermill":{"duration":0.037633,"end_time":"2023-08-14T10:17:39.605345","exception":false,"start_time":"2023-08-14T10:17:39.567712","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:09:59.126880Z","iopub.execute_input":"2023-09-19T03:09:59.127220Z","iopub.status.idle":"2023-09-19T03:10:01.154212Z","shell.execute_reply.started":"2023-09-19T03:09:59.127187Z","shell.execute_reply":"2023-09-19T03:10:01.152619Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 1 test_df = pd.read_csv(\u001b[33m\"\u001b[0m\u001b[33mtest_context.csv\u001b[0m\u001b[33m\"\u001b[0m)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mtest_df.index = \u001b[96mlist\u001b[0m(\u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(test_df)))                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mtest_df[\u001b[33m'\u001b[0m\u001b[33mid\u001b[0m\u001b[33m'\u001b[0m] = \u001b[96mlist\u001b[0m(\u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(test_df)))                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/util/\u001b[0m\u001b[1;33m_decorators.py\u001b[0m:\u001b[94m211\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(msg)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mkwargs[new_arg_name] = new_arg_value                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m211 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, wrapper)                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/util/\u001b[0m\u001b[1;33m_decorators.py\u001b[0m:\u001b[94m331\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mFutureWarning\u001b[0m,                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstacklevel=find_stack_level(),                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m331 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m332 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# attribute \"__signature__\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/\u001b[0m\u001b[1;33mreaders.py\u001b[0m:\u001b[94m950\u001b[0m in \u001b[92mread_csv\u001b[0m             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 947 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 948 \u001b[0m\u001b[2m│   \u001b[0mkwds.update(kwds_defaults)                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 949 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 950 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _read(filepath_or_buffer, kwds)                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 951 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 952 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 953 \u001b[0m\u001b[2m# iterator=True -> TextFileReader\u001b[0m                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/\u001b[0m\u001b[1;33mreaders.py\u001b[0m:\u001b[94m605\u001b[0m in \u001b[92m_read\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 602 \u001b[0m\u001b[2m│   \u001b[0m_validate_names(kwds.get(\u001b[33m\"\u001b[0m\u001b[33mnames\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m))                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 603 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 604 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Create the parser.\u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 605 \u001b[2m│   \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 606 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 607 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m chunksize \u001b[95mor\u001b[0m iterator:                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 608 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m parser                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/\u001b[0m\u001b[1;33mreaders.py\u001b[0m:\u001b[94m1442\u001b[0m in \u001b[92m__init__\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1439 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.options[\u001b[33m\"\u001b[0m\u001b[33mhas_index_names\u001b[0m\u001b[33m\"\u001b[0m] = kwds[\u001b[33m\"\u001b[0m\u001b[33mhas_index_names\u001b[0m\u001b[33m\"\u001b[0m]                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1440 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1441 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.handles: IOHandles | \u001b[94mNone\u001b[0m = \u001b[94mNone\u001b[0m                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1442 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._engine = \u001b[96mself\u001b[0m._make_engine(f, \u001b[96mself\u001b[0m.engine)                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1443 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1444 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mclose\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1445 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.handles \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/\u001b[0m\u001b[1;33mreaders.py\u001b[0m:\u001b[94m1735\u001b[0m in \u001b[92m_make_engine\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1732 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mis_text = \u001b[94mFalse\u001b[0m                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mb\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m mode:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmode += \u001b[33m\"\u001b[0m\u001b[33mb\u001b[0m\u001b[33m\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1735 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.handles = get_handle(                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1736 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mf,                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1737 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmode,                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1738 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mencoding=\u001b[96mself\u001b[0m.options.get(\u001b[33m\"\u001b[0m\u001b[33mencoding\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m),                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/io/\u001b[0m\u001b[1;33mcommon.py\u001b[0m:\u001b[94m856\u001b[0m in \u001b[92mget_handle\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Binary mode does not support 'encoding' and 'newline'.\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m ioargs.encoding \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mb\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m ioargs.mode:                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 855 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Encoding\u001b[0m                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 856 \u001b[2m│   │   │   \u001b[0mhandle = \u001b[96mopen\u001b[0m(                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 857 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhandle,                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 858 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mioargs.mode,                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 859 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mencoding=ioargs.encoding,                                                 \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'test_context.csv'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 test_df = pd.read_csv(<span style=\"color: #808000; text-decoration-color: #808000\">\"test_context.csv\"</span>)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>test_df.index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(test_df)))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>test_df[<span style=\"color: #808000; text-decoration-color: #808000\">'id'</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(test_df)))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/util/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">211</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(msg)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>kwargs[new_arg_name] = new_arg_value                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>211 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, wrapper)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/util/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">331</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">FutureWarning</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stacklevel=find_stack_level(),                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">330 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>331 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">332 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">333 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># attribute \"__signature__\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">readers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">950</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read_csv</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 947 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 948 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>kwds.update(kwds_defaults)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 949 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 950 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _read(filepath_or_buffer, kwds)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 951 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 952 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 953 # iterator=True -&gt; TextFileReader</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">readers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">605</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_read</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 602 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_validate_names(kwds.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"names\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>))                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 603 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 604 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Create the parser.</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 605 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>parser = TextFileReader(filepath_or_buffer, **kwds)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 606 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 607 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> chunksize <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> iterator:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 608 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parser                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">readers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1442</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1439 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.options[<span style=\"color: #808000; text-decoration-color: #808000\">\"has_index_names\"</span>] = kwds[<span style=\"color: #808000; text-decoration-color: #808000\">\"has_index_names\"</span>]                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1440 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1441 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.handles: IOHandles | <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1442 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._make_engine(f, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.engine)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1443 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1444 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">close</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1445 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.handles <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">readers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1735</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_make_engine</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1732 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>is_text = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"b\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> mode:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>mode += <span style=\"color: #808000; text-decoration-color: #808000\">\"b\"</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1735 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.handles = get_handle(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1736 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>f,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>mode,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>encoding=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.options.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"encoding\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>),                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/io/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">common.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">856</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_handle</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Binary mode does not support 'encoding' and 'newline'.</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> ioargs.encoding <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"b\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> ioargs.mode:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 855 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Encoding</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 856 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>handle = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 857 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>handle,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 858 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>ioargs.mode,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 859 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>encoding=ioargs.encoding,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'test_context.csv'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\n","metadata":{"papermill":{"duration":0.026162,"end_time":"2023-08-14T10:18:01.129276","exception":false,"start_time":"2023-08-14T10:18:01.103114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:10:38.415857Z","iopub.execute_input":"2023-09-19T03:10:38.416243Z","iopub.status.idle":"2023-09-19T03:10:38.520222Z","shell.execute_reply.started":"2023-09-19T03:10:38.416208Z","shell.execute_reply":"2023-09-19T03:10:38.519122Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"papermill":{"duration":0.030447,"end_time":"2023-08-14T10:18:01.175589","exception":false,"start_time":"2023-08-14T10:18:01.145142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-19T03:20:37.199207Z","iopub.execute_input":"2023-09-19T03:20:37.199572Z","iopub.status.idle":"2023-09-19T03:20:37.308907Z","shell.execute_reply.started":"2023-09-19T03:20:37.199543Z","shell.execute_reply":"2023-09-19T03:20:37.307793Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model A","metadata":{}},{"cell_type":"code","source":"# model_dir = \"/kaggle/input/llm-science-run-context-2\"\n\n# tokenizer = AutoTokenizer.from_pretrained(model_dir)\n# model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n# model.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n# tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\n# data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n# test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)","metadata":{"papermill":{"duration":0.493618,"end_time":"2023-08-14T10:18:01.685989","exception":false,"start_time":"2023-08-14T10:18:01.192371","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predictions = []\n# for batch in test_dataloader:\n#     for k in batch.keys():\n#         batch[k] = batch[k].cuda()\n#     with torch.no_grad():\n#         outputs = model(**batch)\n#     test_predictions.append(outputs.logits.cpu().detach())\n\n# test_predictions = torch.cat(test_predictions)\n# test_predictions = test_predictions.numpy()","metadata":{"papermill":{"duration":1.101895,"end_time":"2023-08-14T10:18:02.804298","exception":false,"start_time":"2023-08-14T10:18:01.702403","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model From Our Train Notebook","metadata":{}},{"cell_type":"code","source":"# model_dir = \"/kaggle/input/how-to-train-open-book-model/model_v2\"\n# tokenizer = AutoTokenizer.from_pretrained(model_dir)\n# model = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\n# model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predictions2 = []\n# for batch in test_dataloader:\n#     for k in batch.keys():\n#         batch[k] = batch[k].cuda()\n#     with torch.no_grad():\n#         outputs = model(**batch)\n#     test_predictions2.append(outputs.logits.cpu().detach())\n\n# test_predictions2 = torch.cat(test_predictions2)\n# test_predictions = (test_predictions+test_predictions2.numpy()) / 2.0\n\n# predictions_as_ids = np.argsort(-test_predictions, 1)\n\n# predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n# # predictions_as_answer_letters[:3]\n\n# predictions_as_string = test_df['prediction'] = [\n#     ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n# ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = test_df[['id', 'prediction']]\n# submission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.033576,"end_time":"2023-08-14T10:19:17.733491","exception":false,"start_time":"2023-08-14T10:19:17.699915","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# My Model","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\n# deberta-v3-large\n# model_weights = f'../input/jason-trained-models-v3-512/checkpoint-550/checkpoint-550/torch_model'\n# checkpoint_path = f'../input/jason-trained-models-v3-512/checkpoint_18_256-550/checkpoint-550'\n# checkpoint_path = f'../input/jason-trained-models-v3-512/checkpoint_4-450/checkpoint-450'\n# checkpoint_path = f'../input/jason-trained-models-v3-512/checkpoint_12_256-180/checkpoint-180'\n# checkpoint_path = f'/kaggle/input/jason-trained-models-v3-512/checkpoint-290/checkpoint-290' # 18_512\n# checkpoint_path = f'/kaggle/input/jason-trained-models-v3-512/checkpoint_18_512-550/checkpoint-550' # 18_512 \n# checkpoint_path = f'/kaggle/input/jason-trained-models-v3-512/checkpoint-18_256_emb-550/checkpoint-550' # 18_512\n# checkpoint_path = '../input/jason-trained-models-v3-512/18_512_v1_checkpoint-1140/checkpoint-1140'\n# checkpoint_path = '../input/jason-trained-models-v3-512/checkpoint-72/checkpoint-72' # 18 256 v1\n# checkpoint_path = '/kaggle/input/jason-trained-models-v3-512/checkpoint_18_512_v2-86/checkpoint-86' # 18 256 v1\n# checkpoint_path = '/kaggle/input/jason-trained-models-v3-512/checkpoint-266/checkpoint-266' # 16 512 v2 \ncheckpoint_path = '/kaggle/input/jason-trained-models-v3-512/checkpoint_16_512_v6-350/checkpoint-350' # 16 512 v2 \n\n## deberta-v2-xxlarge\n# checkpoint_path = '/kaggle/input/jason-trained-models-v3-512/checkpoint_44_256_v1-480/checkpoint-480'\n\n\npeft_config = LoraConfig.from_pretrained(checkpoint_path)\nmodel_weights = f'{checkpoint_path}/torch_model'\nmodel = AutoModelForMultipleChoice.from_pretrained(model_weights, device_map='cuda:0')\n\n# from peft import LoraConfig, TaskType, get_peft_model\n# peft_config = LoraConfig(\n#     r=8, lora_alpha=4, task_type=TaskType.SEQ_CLS, lora_dropout=0.1, \n#     bias=\"none\", inference_mode=False, \n#     target_modules=[\"query_proj\", \"value_proj\"],\n#     modules_to_save=['classifier','pooler'],\n# )\ntokenizer_weights = checkpoint_path\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_weights)\nmodel = get_peft_model(model, peft_config)\ncheckpoint = torch.load(f'{model_weights}/pytorch_model.bin')\nmodel.base_model.model.load_state_dict(checkpoint)\n# model.eval().cuda()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T03:10:09.411617Z","iopub.execute_input":"2023-09-19T03:10:09.412493Z","iopub.status.idle":"2023-09-19T03:10:38.413671Z","shell.execute_reply.started":"2023-09-19T03:10:09.412448Z","shell.execute_reply":"2023-09-19T03:10:38.412714Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/input/jason-trained-models-v3-512/checkpoint_16_512_v6-350/checkpoint-350/torch_model were not used when initializing DebertaV2ForMultipleChoice: ['deberta.encoder.layer.10.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.6.output.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.1.output.dense.lora_B.default.weight', 'deberta.encoder.layer.22.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.3.output.dense.lora_A.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.13.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.2.output.dense.lora_B.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.17.output.dense.lora_B.default.weight', 'deberta.encoder.layer.9.output.dense.lora_A.default.weight', 'classifier.modules_to_save.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.16.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.17.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.14.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.19.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.5.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.19.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.3.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_A.default.weight', 'pooler.original_module.dense.bias', 'deberta.encoder.layer.4.attention.self.value_proj.lora_A.default.weight', 'classifier.modules_to_save.default.bias', 'deberta.encoder.layer.15.output.dense.lora_A.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.17.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.23.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.output.dense.lora_B.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.0.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.16.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.output.dense.lora_A.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.11.output.dense.lora_B.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.output.dense.lora_A.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.22.output.dense.lora_B.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_B.default.weight', 'pooler.original_module.dense.lora_B.default.weight', 'deberta.encoder.layer.20.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.6.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.13.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.query_proj.lora_B.default.weight', 'pooler.modules_to_save.default.dense.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.14.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.7.output.dense.lora_B.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.8.output.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_A.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.19.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.2.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.10.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.18.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.23.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.14.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.20.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.4.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.5.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.10.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.9.output.dense.lora_B.default.weight', 'deberta.encoder.layer.0.attention.self.key_proj.lora_A.default.weight', 'classifier.original_module.bias', 'deberta.encoder.layer.3.output.dense.lora_B.default.weight', 'deberta.encoder.layer.4.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.12.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.8.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.15.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.2.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.6.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.output.dense.lora_A.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.4.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.16.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.23.attention.self.query_proj.lora_A.default.weight', 'pooler.original_module.dense.lora_A.default.weight', 'deberta.encoder.layer.21.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.13.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.16.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.21.output.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.10.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.10.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.2.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.18.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.8.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.12.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.8.output.dense.lora_A.default.weight', 'deberta.encoder.layer.5.output.dense.lora_B.default.weight', 'deberta.encoder.layer.5.output.dense.lora_A.default.weight', 'deberta.encoder.layer.21.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.15.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.6.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.18.output.dense.lora_A.default.weight', 'deberta.encoder.layer.11.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.19.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.7.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.0.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.22.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.13.output.dense.lora_B.default.weight', 'deberta.encoder.layer.21.output.dense.lora_B.default.weight', 'deberta.encoder.layer.21.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.21.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.14.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.4.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.12.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.self.value_proj.lora_B.default.weight', 'pooler.original_module.dense.weight', 'deberta.encoder.layer.15.output.dense.lora_B.default.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_B.default.weight', 'deberta.encoder.layer.7.attention.self.key_proj.lora_A.default.weight', 'deberta.encoder.layer.15.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.1.output.dense.lora_A.default.weight', 'deberta.encoder.layer.17.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.22.intermediate.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.lora_B.default.weight', 'deberta.encoder.layer.3.attention.self.query_proj.lora_A.default.weight', 'deberta.encoder.layer.23.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.15.attention.output.dense.lora_A.default.weight', 'classifier.original_module.weight', 'deberta.encoder.layer.17.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.5.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.9.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.19.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.14.output.dense.lora_B.default.weight', 'deberta.encoder.layer.13.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.22.attention.self.key_proj.lora_B.default.weight', 'deberta.encoder.layer.20.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.attention.self.value_proj.lora_A.default.weight', 'deberta.encoder.layer.4.output.dense.lora_A.default.weight', 'deberta.encoder.layer.8.attention.self.query_proj.lora_B.default.weight', 'deberta.encoder.layer.23.attention.output.dense.lora_B.default.weight', 'deberta.encoder.layer.1.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.14.intermediate.dense.lora_B.default.weight', 'deberta.encoder.layer.20.output.dense.lora_B.default.weight', 'pooler.modules_to_save.default.dense.bias', 'deberta.encoder.layer.19.intermediate.dense.lora_A.default.weight', 'deberta.encoder.layer.7.attention.output.dense.lora_A.default.weight', 'deberta.encoder.layer.3.attention.output.dense.lora_B.default.weight']\n- This IS expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/jason-trained-models-v3-512/checkpoint_16_512_v6-350/checkpoint-350/torch_model and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"del checkpoint\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T19:59:26.862480Z","iopub.execute_input":"2023-09-18T19:59:26.862840Z","iopub.status.idle":"2023-09-18T19:59:27.268620Z","shell.execute_reply.started":"2023-09-18T19:59:26.862812Z","shell.execute_reply":"2023-09-18T19:59:27.267632Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# model = model.base_model.model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MAX_INPUT =  512\n\n\n# MAX_INPUT =  4096\n\n# MAX_INPUT = 256 \n# MAX_INPUT = 512\n## commenting out max length means no truncation\n\n## This block gets the validation set\n# test_df = pd.read_csv('../input/60k-data-with-context-v2/train_with_context2.csv')\n# test_df.index = list(range(len(test_df)))\n# test_df['id'] = list(range(len(test_df)))\n# # test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:1750]) + \" #### \" +  test_df[\"prompt\"]\n# test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:2500]) + \" #### \" +  test_df[\"prompt\"]\n\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n#     tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True) # truncate should go only first\n    tokenized_example = tokenizer(first_sentence, second_sentence, max_length=MAX_INPUT, truncation='only_first') # truncate should go only first\n#     tokenized_example = tokenizer(first_sentence, second_sentence, truncation='only_first') # truncate should go only first\n\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example\n\ntokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntry:\n    tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\nexcept:\n    print('no need to remove column')\n    pass\n\n\n\n# def preprocess(example):\n#     first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n#     second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n#     tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first',\n#                                   max_length=MAX_INPUT, add_special_tokens=False)\n#     tokenized_example['label'] = option_to_index[example['answer']]\n#     return tokenized_example\n\n# tokenized_test_dataset = Dataset.from_pandas(test_df).map(\n#         preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E'])\n\n\n\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)\n\nwith torch.no_grad():\n    test_predictions = []\n    for batch in test_dataloader:\n        for k in batch.keys():\n            batch[k] = batch[k].cuda()\n        with torch.no_grad():\n            outputs = model(**batch)\n        test_predictions.append(outputs.logits.cpu().detach())\n\ntest_predictions = torch.cat(test_predictions)\ntest_predictions = test_predictions.numpy()\n\n\npredictions_as_ids = np.argsort(-test_predictions, 1)\n\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n# predictions_as_answer_letters[:3]\n\npredictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-19T03:20:40.456778Z","iopub.execute_input":"2023-09-19T03:20:40.458278Z","iopub.status.idle":"2023-09-19T03:22:34.432468Z","shell.execute_reply.started":"2023-09-19T03:20:40.458237Z","shell.execute_reply":"2023-09-19T03:22:34.431425Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d3f745e00b3405c9734da33db15e70b"}},"metadata":{}},{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\nimport numpy as np\ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u].split()\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U\n\nm = MAP_at_3(test_df.prediction.values, test_df.answer.values)\nprint( 'CV MAP@3 =',m )","metadata":{"execution":{"iopub.status.busy":"2023-09-19T03:37:56.293444Z","iopub.execute_input":"2023-09-19T03:37:56.293932Z","iopub.status.idle":"2023-09-19T03:37:56.448110Z","shell.execute_reply.started":"2023-09-19T03:37:56.293894Z","shell.execute_reply":"2023-09-19T03:37:56.447055Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"CV MAP@3 = 0.9108333333333333\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}